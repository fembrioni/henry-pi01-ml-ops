{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es el notebook donde se define y procesa el modelo de recomendación, sobre la base del uso de la distancia coseno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (3.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "import etl_flow as etlflow\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DIRECTORIO_RAIZ=/com.docker.devenvironments.code\n"
     ]
    }
   ],
   "source": [
    "# Variables de ambiente (Para procesamiento en ambiente de desarrollo)\n",
    "%env DIRECTORIO_RAIZ=/com.docker.devenvironments.code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recupero el movies dataset preprocesado\n",
    "m_df = etlflow.obtener_df_preprocesado('m_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar las columnas no utilizadas. Conservar solo id y overview\n",
    "m_df = m_df[['id', 'overview']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, las funciones que permiten el preprocesamiento del modelo de recomendacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimina signos de puntuacion de una lista tokenizada\n",
    "def limpia_signos_de_puntuacion(lista_tokens: list):\n",
    "    token_rta = []\n",
    "    for palabra in lista_tokens:\n",
    "        for letra in palabra:\n",
    "            if letra in string.punctuation:\n",
    "                palabra=palabra.replace(letra,\"\")\n",
    "        token_rta.append(palabra)\n",
    "    return token_rta\n",
    "\n",
    "# Elimina numeros\n",
    "def limpia_numeros(lista_tokens: list):\n",
    "    token_rta = []\n",
    "    for palabra in lista_tokens:\n",
    "        for letra in palabra:\n",
    "            if letra in string.digits:\n",
    "                palabra=palabra.replace(letra,\"\")\n",
    "        token_rta.append(palabra)\n",
    "    return token_rta\n",
    "\n",
    "# Elimina tokens vacios\n",
    "def elimina_tokens_vacios(lista_tokens: list):\n",
    "    token_rta = []\n",
    "    for palabra in lista_tokens:\n",
    "        if palabra != \"\":\n",
    "            token_rta.append(palabra)\n",
    "    return token_rta\n",
    "\n",
    "# Pasa los tokens a minusculas\n",
    "def pasa_tokens_a_minusculas(lista_tokens: list):\n",
    "    token_rta = []\n",
    "    for palabra in lista_tokens:\n",
    "        token_rta.append(palabra.lower())\n",
    "    return token_rta\n",
    "\n",
    "# Elimina tokens cortos\n",
    "def elimina_tokens_cortos(lista_tokens: list):\n",
    "    token_rta = []\n",
    "    for palabra in lista_tokens:\n",
    "        if len(palabra)>=3:\n",
    "            token_rta.append(palabra)\n",
    "    return token_rta\n",
    "\n",
    "# Elimina stop words\n",
    "def elimina_stop_words(lista_tokens: list):\n",
    "    a=set(stopwords.words('english'))\n",
    "    token_rta = [palabra for palabra in lista_tokens if palabra not in a]\n",
    "    return token_rta\n",
    "\n",
    "# Tokeniza el texto y limpia la lista tokenizada\n",
    "def tokenize_and_clean(texto: str):\n",
    "    token = word_tokenize(texto) # Tokenizo\n",
    "    token = limpia_signos_de_puntuacion(token) # Limpio signos de puntuacion\n",
    "    token = limpia_numeros(token) # Limpio números\n",
    "    token = elimina_tokens_vacios(token) # Elimino tokens vacios\n",
    "    token = pasa_tokens_a_minusculas(token) # Paso los tokens a minusculas\n",
    "    token = elimina_tokens_cortos(token) # Elimino tokens cortos\n",
    "    token = elimina_stop_words(token) # Elimino stop words del Inglés, de la lista de tokens\n",
    "    return token\n",
    "\n",
    "# Tokeniza, limpia y vuelve a armar en forma de string\n",
    "def tokenizar_limpiar_y_obtener_string(texto: str):\n",
    "    token_limpio = tokenize_and_clean(texto)\n",
    "    t_str = ' '.join(token_limpio)\n",
    "    return t_str\n",
    "\n",
    "# Serializador / Deserializador de objetos\n",
    "serializados_d = {'mtx_tfidf' : ['src/preproc/mtx_tfidf.tsv', '\\t']}\n",
    "\n",
    "def serializar(nombre_objeto: str, objeto: any):\n",
    "       \n",
    "       if nombre_objeto in serializados_d.keys():\n",
    "\n",
    "              # Obtengo el directorio raiz desde la variable de entorno DIRECTORIO_RAIZ\n",
    "              dir_raiz = os.getenv(\"DIRECTORIO_RAIZ\")\n",
    "\n",
    "              # Escribo el objeto al archivo correspondiente\n",
    "              path_archivo = os.path.join(dir_raiz, serializados_d[nombre_objeto][0])\n",
    "              with open(path_archivo, \"wb\") as archivo:\n",
    "                  pickle.dump(objeto, archivo)\n",
    "\n",
    "       else:\n",
    "\n",
    "              # Error. El serializable no esta en la lista de serializables\n",
    "              print('Error: El serializable no esta en la lista de serializables preprocesados')\n",
    "\n",
    "def deserealizar(nombre_objeto: str):\n",
    "\n",
    "       if nombre_objeto in serializados_d.keys():\n",
    "\n",
    "              # Obtengo el directorio raiz desde la variable de entorno DIRECTORIO_RAIZ\n",
    "              dir_raiz = os.getenv(\"DIRECTORIO_RAIZ\")\n",
    "\n",
    "              # Obtengo el objeto desde el archivo correspondiente\n",
    "              objeto = None\n",
    "              path_archivo = os.path.join(dir_raiz, serializados_d[nombre_objeto][0])\n",
    "              with open(path_archivo, \"rb\") as archivo:\n",
    "                   objeto = pickle.load(archivo)\n",
    "\n",
    "              return objeto\n",
    "       \n",
    "       else:\n",
    "\n",
    "              # Error. El objeto no ha sido preprocesado\n",
    "              print('Error: El objeto no esta en la lista de serializables preprocesados')\n",
    "              return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimino registros con valores nulos en la columna de overview\n",
    "m_df.dropna(subset=['overview'], inplace=True)\n",
    "m_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizo, limpio y rearmo los overviews\n",
    "m_df['cleansed_overview'] = m_df['overview'].apply(tokenizar_limpiar_y_obtener_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancio un count vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armo la matriz Tf-Idf\n",
    "documentos = m_df['cleansed_overview']\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documentos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "serializar('mtx_tfidf', tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix2 = deserealizar('mtx_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0 15271  2976 ... 28123 28121 22210]\n",
      "['led woody andy toys live happily room andy birthday brings buzz lightyear onto scene afraid losing place andy heart woody plots buzz circumstances separate buzz woody owner duo eventually learns put aside differences', 'woody buzz rest andy toys played years andy college gang find accidentally left nefarious day care center toys must band together escape return home andy', 'andy heads cowboy camp leaving toys devices things shift high gear obsessive toy collector named mcwhiggen owner toy barn kidnaps woody andy toys mount daring rescue mission buzz lightyear meets match woody decide heart truly belong', 'andy stitzer pleasant life nice apartment job stamping invoices electronics store age one thing andy done really bothering sexobsessed male coworkers andy still virgin determined help andy get laid guys make mission devirginize seems hopeless andy meets small business owner trish single mom', 'fast food restaurant mini variant buzz forcibly switches places real buzz friends deal obnoxious impostor']\n"
     ]
    }
   ],
   "source": [
    "# Pruebo con un caso\n",
    "# Step 5: Choose a query document\n",
    "query_document = \"Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.\"\n",
    "\n",
    "# Step 6: Find similar documents\n",
    "query_tfidf = tfidf_vectorizer.transform([query_document])\n",
    "similarity_scores = cosine_similarity(query_tfidf, tfidf_matrix2)\n",
    "similarity_scores = similarity_scores.flatten()  # Convert to 1D array\n",
    "related_documents_indices = similarity_scores.argsort()[::-1]  # Sort indices in descending order\n",
    "\n",
    "# Top N similar documents\n",
    "top_n = 5\n",
    "top_documents = [documentos[index] for index in related_documents_indices[:top_n]]\n",
    "\n",
    "print(related_documents_indices)\n",
    "print(top_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaron</th>\n",
       "      <th>aabgamma</th>\n",
       "      <th>aachan</th>\n",
       "      <th>aachi</th>\n",
       "      <th>aackerlund</th>\n",
       "      <th>aadhavan</th>\n",
       "      <th>aadland</th>\n",
       "      <th>aaicha</th>\n",
       "      <th>aakash</th>\n",
       "      <th>...</th>\n",
       "      <th>ரமண</th>\n",
       "      <th>శమ</th>\n",
       "      <th>แพร</th>\n",
       "      <th>たけみかずち</th>\n",
       "      <th>ようなもの</th>\n",
       "      <th>患者さんとその世界</th>\n",
       "      <th>주식회사</th>\n",
       "      <th>첫사랑</th>\n",
       "      <th>ﬁrst</th>\n",
       "      <th>ﬁve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44417</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44418</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44419</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44420</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44421</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44422 rows × 83703 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aaa  aaaron  aabgamma  aachan  aachi  aackerlund  aadhavan  aadland  \\\n",
       "0      0.0     0.0       0.0     0.0    0.0         0.0       0.0      0.0   \n",
       "1      0.0     0.0       0.0     0.0    0.0         0.0       0.0      0.0   \n",
       "2      0.0     0.0       0.0     0.0    0.0         0.0       0.0      0.0   \n",
       "3      0.0     0.0       0.0     0.0    0.0         0.0       0.0      0.0   \n",
       "4      0.0     0.0       0.0     0.0    0.0         0.0       0.0      0.0   \n",
       "...    ...     ...       ...     ...    ...         ...       ...      ...   \n",
       "44417  0.0     0.0       0.0     0.0    0.0         0.0       0.0      0.0   \n",
       "44418  0.0     0.0       0.0     0.0    0.0         0.0       0.0      0.0   \n",
       "44419  0.0     0.0       0.0     0.0    0.0         0.0       0.0      0.0   \n",
       "44420  0.0     0.0       0.0     0.0    0.0         0.0       0.0      0.0   \n",
       "44421  0.0     0.0       0.0     0.0    0.0         0.0       0.0      0.0   \n",
       "\n",
       "       aaicha  aakash  ...  ரமண   శమ  แพร  たけみかずち  ようなもの  患者さんとその世界  주식회사  \\\n",
       "0         0.0     0.0  ...  0.0  0.0  0.0     0.0    0.0        0.0   0.0   \n",
       "1         0.0     0.0  ...  0.0  0.0  0.0     0.0    0.0        0.0   0.0   \n",
       "2         0.0     0.0  ...  0.0  0.0  0.0     0.0    0.0        0.0   0.0   \n",
       "3         0.0     0.0  ...  0.0  0.0  0.0     0.0    0.0        0.0   0.0   \n",
       "4         0.0     0.0  ...  0.0  0.0  0.0     0.0    0.0        0.0   0.0   \n",
       "...       ...     ...  ...  ...  ...  ...     ...    ...        ...   ...   \n",
       "44417     0.0     0.0  ...  0.0  0.0  0.0     0.0    0.0        0.0   0.0   \n",
       "44418     0.0     0.0  ...  0.0  0.0  0.0     0.0    0.0        0.0   0.0   \n",
       "44419     0.0     0.0  ...  0.0  0.0  0.0     0.0    0.0        0.0   0.0   \n",
       "44420     0.0     0.0  ...  0.0  0.0  0.0     0.0    0.0        0.0   0.0   \n",
       "44421     0.0     0.0  ...  0.0  0.0  0.0     0.0    0.0        0.0   0.0   \n",
       "\n",
       "       첫사랑  ﬁrst  ﬁve  \n",
       "0      0.0   0.0  0.0  \n",
       "1      0.0   0.0  0.0  \n",
       "2      0.0   0.0  0.0  \n",
       "3      0.0   0.0  0.0  \n",
       "4      0.0   0.0  0.0  \n",
       "...    ...   ...  ...  \n",
       "44417  0.0   0.0  0.0  \n",
       "44418  0.0   0.0  0.0  \n",
       "44419  0.0   0.0  0.0  \n",
       "44420  0.0   0.0  0.0  \n",
       "44421  0.0   0.0  0.0  \n",
       "\n",
       "[44422 rows x 83703 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo la matriz en formato pandas (BORRAR esta celda luego)\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "pd.DataFrame(tfidf_matrix.toarray(), columns = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>overview</th>\n",
       "      <th>cleansed_overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>led woody andy toys live happily room andy bir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>siblings judy peter discover enchanted board g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>family wedding reignites ancient feud nextdoor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31357</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>cheated mistreated stepped women holding breat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11862</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>george banks recovered daughter wedding receiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44417</th>\n",
       "      <td>30840</td>\n",
       "      <td>Yet another version of the classic epic, with ...</td>\n",
       "      <td>yet another version classic epic enough variat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44418</th>\n",
       "      <td>111109</td>\n",
       "      <td>An artist struggles to finish his work while a...</td>\n",
       "      <td>artist struggles finish work storyline cult pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44419</th>\n",
       "      <td>67758</td>\n",
       "      <td>When one of her hits goes wrong, a professiona...</td>\n",
       "      <td>one hits goes wrong professional assassin ends...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44420</th>\n",
       "      <td>227506</td>\n",
       "      <td>In a small town live two brothers, one a minis...</td>\n",
       "      <td>small town live two brothers one minister one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44421</th>\n",
       "      <td>461257</td>\n",
       "      <td>50 years after decriminalisation of homosexual...</td>\n",
       "      <td>years decriminalisation homosexuality director...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44422 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                           overview  \\\n",
       "0         862  Led by Woody, Andy's toys live happily in his ...   \n",
       "1        8844  When siblings Judy and Peter discover an encha...   \n",
       "2       15602  A family wedding reignites the ancient feud be...   \n",
       "3       31357  Cheated on, mistreated and stepped on, the wom...   \n",
       "4       11862  Just when George Banks has recovered from his ...   \n",
       "...       ...                                                ...   \n",
       "44417   30840  Yet another version of the classic epic, with ...   \n",
       "44418  111109  An artist struggles to finish his work while a...   \n",
       "44419   67758  When one of her hits goes wrong, a professiona...   \n",
       "44420  227506  In a small town live two brothers, one a minis...   \n",
       "44421  461257  50 years after decriminalisation of homosexual...   \n",
       "\n",
       "                                       cleansed_overview  \n",
       "0      led woody andy toys live happily room andy bir...  \n",
       "1      siblings judy peter discover enchanted board g...  \n",
       "2      family wedding reignites ancient feud nextdoor...  \n",
       "3      cheated mistreated stepped women holding breat...  \n",
       "4      george banks recovered daughter wedding receiv...  \n",
       "...                                                  ...  \n",
       "44417  yet another version classic epic enough variat...  \n",
       "44418  artist struggles finish work storyline cult pl...  \n",
       "44419  one hits goes wrong professional assassin ends...  \n",
       "44420  small town live two brothers one minister one ...  \n",
       "44421  years decriminalisation homosexuality director...  \n",
       "\n",
       "[44422 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_df.loc[0, 'overview']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
